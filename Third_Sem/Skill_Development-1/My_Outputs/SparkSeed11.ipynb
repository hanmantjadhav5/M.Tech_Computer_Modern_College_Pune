{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O3Mf4tjGMcuG"
      },
      "outputs": [],
      "source": [
        "# Apache Spark machine learning techniques for developing big data processing applications. using Seeds Dataset give me python code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmylgqFJMqND",
        "outputId": "94ade5d7-5dec-45da-bedd-7f122d568a20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n"
      ],
      "metadata": {
        "id": "Q8-CHvGeQqmD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Seeds Dataset ML with Spark\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "svR38g6DQxl9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load Seeds Dataset\n",
        "# ---------------------------------------------------\n",
        "# Download seeds_dataset.txt from UCI repository\n",
        "# https://archive.ics.uci.edu/ml/datasets/seeds\n",
        "\n",
        "from pyspark.sql.functions import split\n",
        "\n",
        "df = spark.read.text(data_path)\n",
        "\n",
        "df = df.select(\n",
        "    split(df.value, r\"\\s+\").alias(\"data\")\n",
        ")\n",
        "\n",
        "df = df.select(\n",
        "    col(\"data\")[0].cast(\"double\").alias(\"area\"),\n",
        "    col(\"data\")[1].cast(\"double\").alias(\"perimeter\"),\n",
        "    col(\"data\")[2].cast(\"double\").alias(\"compactness\"),\n",
        "    col(\"data\")[3].cast(\"double\").alias(\"kernel_length\"),\n",
        "    col(\"data\")[4].cast(\"double\").alias(\"kernel_width\"),\n",
        "    col(\"data\")[5].cast(\"double\").alias(\"asymmetry\"),\n",
        "    col(\"data\")[6].cast(\"double\").alias(\"groove_length\"),\n",
        "    col(\"data\")[7].cast(\"int\").alias(\"label\")\n",
        ")\n",
        "\n",
        "df.show(5)\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUVh7sSiQ3r3",
        "outputId": "f0b8b0c1-47fc-4500-debd-36feca5e2390"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+-----------+-------------+------------+---------+-------------+-----+\n",
            "| area|perimeter|compactness|kernel_length|kernel_width|asymmetry|groove_length|label|\n",
            "+-----+---------+-----------+-------------+------------+---------+-------------+-----+\n",
            "|15.26|    14.84|      0.871|        5.763|       3.312|    2.221|         5.22|    1|\n",
            "|14.88|    14.57|     0.8811|        5.554|       3.333|    1.018|        4.956|    1|\n",
            "|14.29|    14.09|      0.905|        5.291|       3.337|    2.699|        4.825|    1|\n",
            "|13.84|    13.94|     0.8955|        5.324|       3.379|    2.259|        4.805|    1|\n",
            "|16.14|    14.99|     0.9034|        5.658|       3.562|    1.355|        5.175|    1|\n",
            "+-----+---------+-----------+-------------+------------+---------+-------------+-----+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- area: double (nullable = true)\n",
            " |-- perimeter: double (nullable = true)\n",
            " |-- compactness: double (nullable = true)\n",
            " |-- kernel_length: double (nullable = true)\n",
            " |-- kernel_width: double (nullable = true)\n",
            " |-- asymmetry: double (nullable = true)\n",
            " |-- groove_length: double (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature Vectorization\n",
        "# ---------------------------------------------------\n",
        "feature_cols = columns[:-1]  # exclude label\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "df_vector = assembler.transform(df)"
      ],
      "metadata": {
        "id": "O_Xr7rgHSt0X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Feature Scaling\n",
        "# ---------------------------------------------------\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features\",\n",
        "    outputCol=\"scaled_features\",\n",
        "    withMean=True,\n",
        "    withStd=True\n",
        ")\n",
        "\n",
        "scaler_model = scaler.fit(df_vector)\n",
        "df_scaled = scaler_model.transform(df_vector)"
      ],
      "metadata": {
        "id": "bEle6slETCn-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train-Test Split\n",
        "# ---------------------------------------------------\n",
        "train_df, test_df = df_scaled.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "P5KrWkb4TFp3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Logistic Regression Classification\n",
        "# ---------------------------------------------------\n",
        "lr = LogisticRegression(\n",
        "    featuresCol=\"scaled_features\",\n",
        "    labelCol=\"label\",\n",
        "    maxIter=100\n",
        ")\n",
        "\n",
        "lr_model = lr.fit(train_df)\n",
        "lr_predictions = lr_model.transform(test_df)\n",
        "\n",
        "lr_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "lr_accuracy = lr_evaluator.evaluate(lr_predictions)\n",
        "print(\"Logistic Regression Accuracy:\", lr_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg59aa8wTJqJ",
        "outputId": "0823bcd7-01c3-4500-99e6-c598f67184a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Decision Tree Classification\n",
        "# ---------------------------------------------------\n",
        "dt = DecisionTreeClassifier(\n",
        "    featuresCol=\"scaled_features\",\n",
        "    labelCol=\"label\",\n",
        "    maxDepth=5\n",
        ")\n",
        "\n",
        "dt_model = dt.fit(train_df)\n",
        "dt_predictions = dt_model.transform(test_df)\n",
        "\n",
        "dt_accuracy = lr_evaluator.evaluate(dt_predictions)\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwjN2YuoTNTT",
        "outputId": "5dc1b397-0902-41fb-8a12-f484405a9440"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.96875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. K-Means Clustering (Unsupervised Learning)\n",
        "# ---------------------------------------------------\n",
        "kmeans = KMeans(\n",
        "    featuresCol=\"scaled_features\",\n",
        "    k=3,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "kmeans_model = kmeans.fit(df_scaled)\n",
        "kmeans_predictions = kmeans_model.transform(df_scaled)\n",
        "\n",
        "cluster_evaluator = ClusteringEvaluator(\n",
        "    featuresCol=\"scaled_features\",\n",
        "    metricName=\"silhouette\"\n",
        ")\n",
        "\n",
        "silhouette_score = cluster_evaluator.evaluate(kmeans_predictions)\n",
        "print(\"K-Means Silhouette Score:\", silhouette_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgAfP1ccTQzt",
        "outputId": "0bb57a76-7ffe-43ae-87fc-def3ca2ee9a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Means Silhouette Score: 0.5928460025426404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Stop Spark Session\n",
        "# ---------------------------------------------------\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "DCAmSY3QTWn-"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}